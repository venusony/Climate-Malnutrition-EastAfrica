{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89f13e6-5d31-402c-a0b3-e46fd99618ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIPs here: C:\\Users\\venus\\OneDrive\\Documents\\GitHub\\Climate-Malnutrition-EastAfrica\\data_raw\\DHS_zip\n",
      "DTA out: C:\\Users\\venus\\OneDrive\\Documents\\GitHub\\Climate-Malnutrition-EastAfrica\\data_raw\\DHS_dta\n",
      "Clean raw CSV: C:\\Users\\venus\\OneDrive\\Documents\\GitHub\\Climate-Malnutrition-EastAfrica\\data_cleaned\\dhs_raw_csv\n",
      "Clean tidy CSV: C:\\Users\\venus\\OneDrive\\Documents\\GitHub\\Climate-Malnutrition-EastAfrica\\data_cleaned\\dhs_clean_csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "REPO   = Path(\"..\")\n",
    "RAW_ZIP = REPO / \"data_raw\" / \"DHS_zip\"\n",
    "RAW_DTA = REPO / \"data_raw\" / \"DHS_dta\"\n",
    "CLEAN   = REPO / \"data_cleaned\"\n",
    "CLEAN_RAW = CLEAN / \"dhs_raw_csv\"\n",
    "CLEAN_TIDY = CLEAN / \"dhs_clean_csv\"\n",
    "\n",
    "for p in [RAW_ZIP, RAW_DTA, CLEAN_RAW, CLEAN_TIDY]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ZIPs here:\", RAW_ZIP.resolve())\n",
    "print(\"DTA out:\", RAW_DTA.resolve())\n",
    "print(\"Clean raw CSV:\", CLEAN_RAW.resolve())\n",
    "print(\"Clean tidy CSV:\", CLEAN_TIDY.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d241cdbe-cd10-4593-854d-2be874b46ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted from: ETKR41DT.zip\n",
      "Extracted from: ETKR51DT.zip\n",
      "Extracted from: ETKR61DT.zip\n",
      "Extracted from: ETKR71DT.zip\n",
      "Extracted from: ETKR81DT.zip\n",
      "Extracted from: KEKR01DT.zip\n",
      "Extracted from: KEKR31DT.zip\n",
      "Extracted from: KEKR3ADT.zip\n",
      "Extracted from: KEKR42DT.zip\n",
      "Extracted from: KEKR52DT.zip\n",
      "Extracted from: KEKR72DT.zip\n",
      "Extracted from: KEKR8CDT.zip\n",
      "Extracted from: TZKR21DT.zip\n",
      "Extracted from: TZKR3ADT.zip\n",
      "Extracted from: TZKR41DT.zip\n",
      "Extracted from: TZKR4IDT.zip\n",
      "Extracted from: TZKR63DT.zip\n",
      "Extracted from: TZKR7BDT.zip\n",
      "Extracted from: TZKR82DT.zip\n",
      "Extracted from: UGKR01DT.zip\n",
      "Extracted from: UGKR33DT.zip\n",
      "Extracted from: UGKR41DT.zip\n",
      "Extracted from: UGKR52DT.zip\n",
      "Extracted from: UGKR61DT.zip\n",
      "Extracted from: UGKR7BDT.zip\n",
      "Total .DTA extracted: 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25,\n",
       " [WindowsPath('../data_raw/DHS_dta/ETKR41FL.DTA'),\n",
       "  WindowsPath('../data_raw/DHS_dta/ETKR51FL.DTA'),\n",
       "  WindowsPath('../data_raw/DHS_dta/ETKR61FL.DTA'),\n",
       "  WindowsPath('../data_raw/DHS_dta/ETKR71FL.DTA'),\n",
       "  WindowsPath('../data_raw/DHS_dta/ETKR81FL.DTA')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for zpath in RAW_ZIP.glob(\"*.zip\"):\n",
    "    with zipfile.ZipFile(zpath) as zf:\n",
    "        for name in zf.namelist():\n",
    "            if name.lower().endswith(\".dta\"):\n",
    "                zf.extract(name, RAW_DTA)\n",
    "                src = RAW_DTA / name\n",
    "                flat = RAW_DTA / Path(name).name\n",
    "                if src.exists() and src != flat:\n",
    "                    src.rename(flat)\n",
    "                count += 1\n",
    "    print(\"Extracted from:\", zpath.name)\n",
    "print(\"Total .DTA extracted:\", count)\n",
    "\n",
    "dta_files = sorted(RAW_DTA.glob(\"*.DTA\"))\n",
    "len(dta_files), dta_files[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8658aee-e20e-4b2f-b0ba-513d2e8dc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_cols(df):\n",
    "    cols = set(df.columns)\n",
    "    def pick(*candidates):\n",
    "        for c in candidates:\n",
    "            if c in cols:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    mapping = {\n",
    "        \"height_for_age_z\": pick(\"hw70\",\"hc70\"),\n",
    "        \"weight_for_height_z\": pick(\"hw71\",\"hc71\"),\n",
    "        \"weight_for_age_z\": pick(\"hw72\",\"hc72\"),\n",
    "        \"sex\": pick(\"b4\"),\n",
    "        \"age_months\": pick(\"b19\"),\n",
    "        \"mother_edu\": pick(\"v106\"),\n",
    "        \"wealth_quintile\": pick(\"v190\"),\n",
    "        \"residence\": pick(\"v025\"),\n",
    "        \"region\": pick(\"v024\"),\n",
    "        \"year\": pick(\"v007\"),\n",
    "        \"weight_raw\": pick(\"v005\"),\n",
    "    }\n",
    "    return {k:v for k,v in mapping.items() if v is not None}\n",
    "\n",
    "def clean_one_dhs(dta_path: Path):\n",
    "    df = pd.read_stata(dta_path, convert_categoricals=False)\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    cols = resolve_cols(df)\n",
    "    if not {\"height_for_age_z\",\"weight_for_height_z\",\"weight_for_age_z\"}.intersection(cols.keys()):\n",
    "        raise ValueError(f\"No nutrition z-score columns found in {dta_path.name}\")\n",
    "\n",
    "    sub = df[list(cols.values())].copy()\n",
    "    sub.columns = list(cols.keys())\n",
    "\n",
    "    # plausible ranges\n",
    "    for z in [\"height_for_age_z\",\"weight_for_height_z\",\"weight_for_age_z\"]:\n",
    "        if z in sub:\n",
    "            sub = sub[(sub[z].between(-6,6)) | sub[z].isna()]\n",
    "\n",
    "    # readable labels\n",
    "    if \"mother_edu\" in sub:\n",
    "        sub[\"mother_edu\"] = sub[\"mother_edu\"].map({0:\"none\",1:\"primary\",2:\"secondary\",3:\"higher\"}).fillna(sub[\"mother_edu\"])\n",
    "    if \"wealth_quintile\" in sub:\n",
    "        sub[\"wealth_quintile\"] = sub[\"wealth_quintile\"].map({1:\"poorest\",2:\"poorer\",3:\"middle\",4:\"richer\",5:\"richest\"}).fillna(sub[\"wealth_quintile\"])\n",
    "    if \"residence\" in sub:\n",
    "        sub[\"residence\"] = sub[\"residence\"].map({1:\"urban\",2:\"rural\"}).fillna(sub[\"residence\"])\n",
    "\n",
    "    # sample weight\n",
    "    if \"weight_raw\" in sub:\n",
    "        sub[\"weight\"] = sub[\"weight_raw\"] / 1_000_000.0\n",
    "\n",
    "    # add country from filename prefix\n",
    "    code = dta_path.name[:2].upper()\n",
    "    code2name = {\"ET\":\"Ethiopia\",\"KE\":\"Kenya\",\"TZ\":\"Tanzania\",\"UG\":\"Uganda\"}\n",
    "    sub[\"country\"] = code2name.get(code, code)\n",
    "\n",
    "    # ensure integer year if present\n",
    "    if \"year\" in sub:\n",
    "        sub[\"year\"] = pd.to_numeric(sub[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # final tidy column order\n",
    "    order = [\"country\",\"year\",\"weight\",\"age_months\",\"sex\",\n",
    "             \"height_for_age_z\",\"weight_for_height_z\",\"weight_for_age_z\",\n",
    "             \"mother_edu\",\"wealth_quintile\",\"residence\",\"region\",\"weight_raw\"]\n",
    "    sub = sub[[c for c in order if c in sub.columns]]\n",
    "\n",
    "    return df, sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64020fe4-2ccf-4b1b-bf5e-b1d93e346247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip: ETKR41FL.DTA No nutrition z-score columns found in ETKR41FL.DTA\n",
      "Skip: ETKR51FL.DTA No nutrition z-score columns found in ETKR51FL.DTA\n",
      "OK: ETKR61FL.DTA rows raw: 11654 rows clean: 1181\n",
      "OK: ETKR71FL.DTA rows raw: 10641 rows clean: 1521\n",
      "OK: ETKR81FL.DTA rows raw: 5753 rows clean: 550\n",
      "Skip: KEKR01FL.DTA No nutrition z-score columns found in KEKR01FL.DTA\n",
      "Skip: KEKR31FL.DTA No nutrition z-score columns found in KEKR31FL.DTA\n",
      "Skip: KEKR3AFL.DTA No nutrition z-score columns found in KEKR3AFL.DTA\n",
      "Skip: KEKR42FL.DTA No nutrition z-score columns found in KEKR42FL.DTA\n",
      "OK: KEKR52FL.DTA rows raw: 6079 rows clean: 591\n",
      "OK: KEKR72FL.DTA rows raw: 20964 rows clean: 2077\n",
      "OK: KEKR8CFL.DTA rows raw: 19530 rows clean: 2133\n",
      "Skip: TZKR21FL.DTA No nutrition z-score columns found in TZKR21FL.DTA\n",
      "Skip: TZKR3AFL.DTA No nutrition z-score columns found in TZKR3AFL.DTA\n",
      "Skip: TZKR41FL.DTA No nutrition z-score columns found in TZKR41FL.DTA\n",
      "Skip: TZKR4IFL.DTA No nutrition z-score columns found in TZKR4IFL.DTA\n",
      "OK: TZKR63FL.DTA rows raw: 8023 rows clean: 851\n",
      "OK: TZKR7BFL.DTA rows raw: 10233 rows clean: 1169\n",
      "OK: TZKR82FL.DTA rows raw: 10783 rows clean: 5925\n",
      "Skip: UGKR01FL.DTA No nutrition z-score columns found in UGKR01FL.DTA\n",
      "Skip: UGKR33FL.DTA No nutrition z-score columns found in UGKR33FL.DTA\n",
      "Skip: UGKR41FL.DTA No nutrition z-score columns found in UGKR41FL.DTA\n",
      "OK: UGKR52FL.DTA rows raw: 8369 rows clean: 5852\n",
      "OK: UGKR61FL.DTA rows raw: 7878 rows clean: 5665\n",
      "OK: UGKR7BFL.DTA rows raw: 15522 rows clean: 11067\n",
      "Raw CSV files: 12 Clean CSV files: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ETKR41FL.DTA', 'No nutrition z-score columns found in ETKR41FL.DTA'),\n",
       " ('ETKR51FL.DTA', 'No nutrition z-score columns found in ETKR51FL.DTA'),\n",
       " ('KEKR01FL.DTA', 'No nutrition z-score columns found in KEKR01FL.DTA'),\n",
       " ('KEKR31FL.DTA', 'No nutrition z-score columns found in KEKR31FL.DTA'),\n",
       " ('KEKR3AFL.DTA', 'No nutrition z-score columns found in KEKR3AFL.DTA')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WRITE_RAW = True  # set to False if you only want cleaned\n",
    "raw_written = 0\n",
    "clean_written = 0\n",
    "problems = []\n",
    "\n",
    "for f in dta_files:\n",
    "    try:\n",
    "        raw_df, clean_df = clean_one_dhs(f)\n",
    "\n",
    "        # raw\n",
    "        if WRITE_RAW:\n",
    "            raw_path = CLEAN_RAW / f\"{f.stem.lower()}_raw.csv\"\n",
    "            raw_df.to_csv(raw_path, index=False)\n",
    "            raw_written += 1\n",
    "\n",
    "        # tidy\n",
    "        tidy_path = CLEAN_TIDY / f\"{f.stem.lower()}_clean.csv\"\n",
    "        clean_df.to_csv(tidy_path, index=False)\n",
    "        clean_written += 1\n",
    "\n",
    "        print(\"OK:\", f.name, \"rows raw:\", len(raw_df), \"rows clean:\", len(clean_df))\n",
    "    except Exception as e:\n",
    "        problems.append((f.name, str(e)))\n",
    "        print(\"Skip:\", f.name, str(e)[:120])\n",
    "\n",
    "print(\"Raw CSV files:\", raw_written, \"Clean CSV files:\", clean_written)\n",
    "problems[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d406ddfd-8a86-4dcb-9a3e-5b23d4ebe101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined rows: 38582 Columns: ['country', 'year', 'weight', 'sex', 'height_for_age_z', 'weight_for_height_z', 'weight_for_age_z', 'mother_edu', 'wealth_quintile', 'residence', 'region', 'weight_raw', 'age_months']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(WindowsPath('../data_cleaned/dhs_children_all_rounds_clean.csv'),\n",
       " WindowsPath('../data_cleaned/dhs_children_2010_2024_clean.csv'),\n",
       " country   year\n",
       " Ethiopia  2011      550\n",
       " Kenya     2014     2077\n",
       "           2022     2133\n",
       " Tanzania  2010      759\n",
       "           2015      888\n",
       "           2016      281\n",
       "           2022     5925\n",
       " Uganda    2011     5665\n",
       "           2016    11067\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_parts = []\n",
    "for cpath in sorted(CLEAN_TIDY.glob(\"*_clean.csv\")):\n",
    "    try:\n",
    "        clean_parts.append(pd.read_csv(cpath))\n",
    "    except Exception as e:\n",
    "        print(\"Cannot read cleaned file:\", cpath.name, e)\n",
    "\n",
    "panel = pd.concat(clean_parts, ignore_index=True) if clean_parts else pd.DataFrame()\n",
    "print(\"Combined rows:\", len(panel), \"Columns:\", list(panel.columns))\n",
    "\n",
    "# optional filter to your study window\n",
    "panel_2010_2024 = panel.copy()\n",
    "if \"year\" in panel_2010_2024:\n",
    "    panel_2010_2024 = panel_2010_2024[panel_2010_2024[\"year\"].between(2010, 2024, inclusive=\"both\")]\n",
    "\n",
    "panel_path_all = CLEAN / \"dhs_children_all_rounds_clean.csv\"\n",
    "panel_path_win = CLEAN / \"dhs_children_2010_2024_clean.csv\"\n",
    "\n",
    "panel.to_csv(panel_path_all, index=False)\n",
    "panel_2010_2024.to_csv(panel_path_win, index=False)\n",
    "\n",
    "panel_path_all, panel_path_win, panel_2010_2024.groupby([\"country\",\"year\"]).size().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953e65a0-cb20-450a-b3a9-a5a5b18f8b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    country  year    weight  sex  height_for_age_z  weight_for_height_z  \\\n",
       " 0  Ethiopia  2011  1.543343    1               NaN                  NaN   \n",
       " 1  Ethiopia  2011  1.543343    2               NaN                  NaN   \n",
       " 2  Ethiopia  2011  1.543343    1               NaN                  NaN   \n",
       " \n",
       "    weight_for_age_z mother_edu wealth_quintile residence  region  weight_raw  \\\n",
       " 0               NaN     higher         richest     urban       1     1543343   \n",
       " 1               NaN  secondary         richest     urban       1     1543343   \n",
       " 2               NaN       none         richest     urban       1     1543343   \n",
       " \n",
       "    age_months  \n",
       " 0         9.0  \n",
       " 1        40.0  \n",
       " 2        10.0  ,\n",
       " WindowsPath('../data_cleaned/dhs_children_2010_2024_clean.csv'),\n",
       " (29345, 13))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "REPO  = Path(\"..\")\n",
    "CLEAN = REPO / \"data_cleaned\"\n",
    "\n",
    "panel_path_all = CLEAN / \"dhs_children_all_rounds_clean.csv\"\n",
    "panel_path_win = CLEAN / \"dhs_children_2010_2024_clean.csv\"\n",
    "\n",
    "# prefer your study window if it exists\n",
    "use_path = panel_path_win if panel_path_win.exists() else panel_path_all\n",
    "df = pd.read_csv(use_path)\n",
    "\n",
    "df.head(3), use_path, df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aacef80-a98e-448b-92fa-5342a479be5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
